# An√°lisis de Sentimiento de Rese√±as de Pel√≠culas con BiLSTM

**Autores:** Daniel Brand Taborda, Jhonier Ra√∫l Jim√©nez
**Curso:** Deep Learning - 2025

**Enlace del video:** https://youtu.be/iSqDng-TPaw

---

## üìù Descripci√≥n del Proyecto

Este repositorio contiene la soluci√≥n para un proyecto de an√°lisis de sentimiento, cuyo objetivo es clasificar rese√±as de pel√≠culas del famoso **dataset IMDB** como **positivas** o **negativas**.

Para lograrlo, se implement√≥ un modelo de Deep Learning basado en una **Red Neuronal Recurrente Bidireccional (BiLSTM)**. El proyecto abarca desde el an√°lisis exploratorio de los datos y su preprocesamiento (limpieza, lematizaci√≥n, tokenizaci√≥n) hasta el entrenamiento y la evaluaci√≥n rigurosa del modelo.

---

## üé• Video de Presentaci√≥n

En el siguiente video se encuentra la presentaci√≥n ejecutiva del proyecto, explicando la metodolog√≠a, la arquitectura y los resultados obtenidos.

üëâ **Enlace al video:** **[AQU√ç DEBES PEGAR EL ENLACE A TU VIDEO DE YOUTUBE]**

---

## üìä Resultados

El modelo final, tras ser entrenado durante 5 √©pocas, alcanz√≥ un rendimiento s√≥lido y balanceado en el conjunto de prueba (datos nunca antes vistos):

* **Exactitud (Accuracy) General:** **86.6%**
* **F1-Score (Promedio):** **87%**

---

## üóÇÔ∏è Estructura del Repositorio

El proyecto est√° organizado de manera modular para facilitar su comprensi√≥n y reproducibilidad.

* **/data**: Contiene el dataset original `IMDB Dataset.csv`.
* **/processed_data**: Contiene los datos de entrenamiento y prueba ya limpios y preprocesados, listos para ser consumidos por el modelo.
* `01 - exploraci√≥n de datos.ipynb`: Notebook para el An√°lisis Exploratorio de Datos (EDA).
* `02 - preprocesado.ipynb`: Notebook que realiza toda la limpieza y preparaci√≥n de los datos de texto.
* `03 - arquitectura de linea de base.ipynb`: Notebook donde se define la arquitectura del modelo BiLSTM y se preparan las secuencias (tokenizaci√≥n y padding).
* `04 - entrenamiento y evaluacion.ipynb`: Notebook para entrenar, evaluar el modelo y visualizar los resultados.
* `sentiment_model.h5`: El modelo final entrenado y guardado.
* `tokenizer_config.json`: El objeto Tokenizer de Keras guardado, esencial para procesar nuevas rese√±as con el mismo vocabulario.
* `requirements.txt`: Archivo con las dependencias exactas del proyecto.
* `INFORME_PROYECTO.PDF`: El informe ejecutivo detallado del proyecto.
* `ENTREGA1.PDF`: El informe de la primera entrega del proyecto.

---

## üöÄ C√≥mo Ejecutar el Proyecto

Para replicar los resultados, puedes seguir estos pasos.

### Prerrequisitos

* Python 3.8 o superior
* Pip (manejador de paquetes de Python)

### Instalaci√≥n en un Entorno Local

1.  **Clona el repositorio:**
    ```bash
    git clone [URL-DE-TU-REPOSITORIO]
    cd [NOMBRE-DEL-REPOSITORIO]
    ```

2.  **Crea y activa un entorno virtual (recomendado):**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # En Windows: .venv\Scripts\activate
    ```

3.  **Instala las dependencias:**
    El archivo `requirements.txt` contiene todas las librer√≠as necesarias con sus versiones exactas. Inst√°lalas con el siguiente comando:
    ```bash
    pip install -r requirements.txt
    ```
    Las dependencias clave son:
    - `tensorflow==2.19.0`
    - `pandas==2.3.0`
    - `numpy==2.3.1`
    - `scikit-learn==1.7.0`
    - `nltk==3.9.1`
    - `matplotlib==3.10.3`
    - `seaborn==0.13.2`

    *Nota: La primera vez que ejecutes el notebook de preprocesado, NLTK podr√≠a necesitar descargar componentes adicionales como `wordnet` y `stopwords`.*

4.  **Ejecuta los notebooks en orden:**
    Abre Jupyter Notebook o Jupyter Lab y ejecuta los notebooks en el siguiente orden num√©rico para replicar el pipeline completo:
    1.  `01 - exploraci√≥n de datos.ipynb`
    2.  `02 - preprocesado.ipynb`
    3.  `03 - arquitectura de linea de base.ipynb`
    4.  `04 - entrenamiento y evaluacion.ipynb`

### Ejecuci√≥n en Google Colab

Alternativamente, los notebooks est√°n dise√±ados para ser **directamente reproducibles en Google Colab**. Simplemente sube la carpeta del proyecto a tu Google Drive, o clona el repositorio directamente en una celda de Colab, y ejecuta los notebooks en orden.

---

## üíæ Dataset

El conjunto de datos utilizado es el **"IMDB Dataset of 50K Movie Reviews"**, disponible p√∫blicamente en Kaggle.

* **Enlace:** [https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Lenguaje:** Python
* **Deep Learning:** TensorFlow / Keras
* **Procesamiento de Lenguaje Natural:** NLTK
* **Manipulaci√≥n de Datos:** Pandas, NumPy
* **Visualizaci√≥n:** Matplotlib, Seaborn
* **Entorno:** Jupyter Notebooks, Google Colab

---

¬°Gracias por revisar el proyecto!